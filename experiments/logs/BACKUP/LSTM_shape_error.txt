+ echo Logging output to experiments/logs/vgg16_voc_2007_trainval__vgg16.txt.2017-11-22_12-21-16
Logging output to experiments/logs/vgg16_voc_2007_trainval__vgg16.txt.2017-11-22_12-21-16
+ set +x
+ '[' '!' -f output/vgg16/voc_2007_trainval/default/vgg16_faster_rcnn_iter_70000.ckpt.index ']'
+ [[ ! -z '' ]]
+ python ./tools/trainval_net.py --weight data/imagenet_weights/vgg16.ckpt --imdb voc_2007_trainval --imdbval voc_2007_test --iters 70000 --cfg experiments/cfgs/vgg16.yml --net vgg16 --set ANCHOR_SCALES '[8,16,32]' ANCHOR_RATIOS '[0.5,1,2]' TRAIN.STEPSIZE '[50000]'
Couldn't import dot_parser, loading of dot files will not be possible.
Called with args:
Namespace(cfg_file='experiments/cfgs/vgg16.yml', imdb_name='voc_2007_trainval', imdbval_name='voc_2007_test', max_iters=70000, net='vgg16', set_cfgs=['ANCHOR_SCALES', '[8,16,32]', 'ANCHOR_RATIOS', '[0.5,1,2]', 'TRAIN.STEPSIZE', '[50000]'], tag=None, weight='data/imagenet_weights/vgg16.ckpt')
Using config:
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32],
 'DATA_DIR': '/home/anguyen/workspace/paper_src/2018.iros.ood.source/main/tf-faster-rcnn/data',
 'DEBUG_VERBOSE': 1,
 'EXP_DIR': 'vgg16',
 'IXTOWORD_PATH': '/home/anguyen/workspace/paper_src/2018.iros.ood.source/main/tf-faster-rcnn/data/VOCdevkit2007/VOC2007/Words/ixtoword.npy',
 'MATLAB': 'matlab',
 'MAX_PHRASE_LENGTH': 10,
 'MOBILENET': {'DEPTH_MULTIPLIER': 1.0,
               'FIXED_LAYERS': 5,
               'REGU_DEPTH': False,
               'WEIGHT_DECAY': 4e-05},
 'PIXEL_MEANS': array([[[ 102.9801,  115.9465,  122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'RESNET': {'FIXED_BLOCKS': 1, 'MAX_POOL': False},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/anguyen/workspace/paper_src/2018.iros.ood.source/main/tf-faster-rcnn',
 'RPN_CHANNELS': 512,
 'SPECIAL_TOKEN': 0,
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1000,
          'MODE': 'nms',
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'gt',
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'RPN_TOP_N': 5000,
          'SCALES': [600],
          'SVM': False},
 'TRAIN': {'ASPECT_GROUPING': False,
           'BATCH_SIZE': 256,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'BIAS_DECAY': False,
           'DISPLAY': 20,
           'DOUBLE_BIAS': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'GAMMA': 0.1,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'LEARNING_RATE': 0.001,
           'MAX_SIZE': 1000,
           'MOMENTUM': 0.9,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_ITERS': 5000,
           'SNAPSHOT_KEPT': 3,
           'SNAPSHOT_PREFIX': 'vgg16_faster_rcnn',
           'STEPSIZE': [50000],
           'SUMMARY_INTERVAL': 180,
           'TRUNCATED': False,
           'USE_ALL_GT': True,
           'USE_FLIPPED': True,
           'USE_GT': False,
           'WEIGHT_DECAY': 0.0001},
 'USE_GPU_NMS': True,
 'VIS_VERBOSE': 0,
 'batch_size': 1,
 'bias_init_vector': None,
 'dim_img_feature': 49,
 'num_lstm_hidden_units': 512,
 'num_lstm_steps': 10,
 'vocab_size': 210}
--- trainval_net.py - IMDB name:  voc_2007_trainval
Loaded dataset `voc_2007_trainval` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
voc_2007_trainval gt roidb loaded from /home/anguyen/workspace/paper_src/2018.iros.ood.source/main/tf-faster-rcnn/data/cache/voc_2007_trainval_gt_roidb.pkl
done
Preparing training data...
done
140 roidb entries
Output will be saved to `/home/anguyen/workspace/paper_src/2018.iros.ood.source/main/tf-faster-rcnn/output/vgg16/voc_2007_trainval/default`
TensorFlow summaries will be saved to `/home/anguyen/workspace/paper_src/2018.iros.ood.source/main/tf-faster-rcnn/tensorboard/vgg16/voc_2007_trainval/default`
Loaded dataset `voc_2007_test` for training
Set proposal method: gt
Preparing training data...
voc_2007_test gt roidb loaded from /home/anguyen/workspace/paper_src/2018.iros.ood.source/main/tf-faster-rcnn/data/cache/voc_2007_test_gt_roidb.pkl
done
30 validation roidb entries
Filtered 0 roidb entries: 140 -> 140
Filtered 0 roidb entries: 30 -> 30
2017-11-22 12:21:18.217639: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2017-11-22 12:21:18.468114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
pciBusID: 0000:03:00.0
totalMemory: 11.92GiB freeMemory: 11.42GiB
2017-11-22 12:21:18.468149: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0, compute capability: 5.2)
Solving...
network.py ************** rois shape                <unknown>
network.py ************** roi_scores shape          <unknown>
network.py ************** labels shape              <unknown>
network.py ************** bbox_targets shape        <unknown>
network.py ************** bbox_inside_weights shape <unknown>
network.py ************** sentences shape           <unknown>
network.py ************** answers   shape           <unknown>
network.py ############## rois shape                (256, 5)
network.py ############## roi_scores shape          (256,)
network.py ############## labels shape              (256, 1)
network.py ############## bbox_targets shape        (256, 20)
network.py ############## bbox_inside_weights shape (256, 20)
network.py ############## sentences shape           (256, 10)
network.py ############## answers   shape           (256, 10)
network.py ++++++++++++++ fc7 shape                 (256, 4096)
network.py ++++++++++++++ pool5 shape               (256, 7, 7, 512)
network.py ++++++++++++++ sentences shape           (256, 10)
network.py ++++++++++++++ answers   shape           (256, 10)
Traceback (most recent call last):
  File "./tools/trainval_net.py", line 143, in <module>
    max_iters=args.max_iters)
  File "/home/anguyen/workspace/paper_src/2018.iros.ood.source/main/tf-faster-rcnn/tools/../lib/model/train_val.py", line 380, in train_net
    sw.train_model(sess, max_iters)
  File "/home/anguyen/workspace/paper_src/2018.iros.ood.source/main/tf-faster-rcnn/tools/../lib/model/train_val.py", line 248, in train_model
    lr, train_op = self.construct_graph(sess)
  File "/home/anguyen/workspace/paper_src/2018.iros.ood.source/main/tf-faster-rcnn/tools/../lib/model/train_val.py", line 123, in construct_graph
    anchor_ratios=cfg.ANCHOR_RATIOS)
  File "/home/anguyen/workspace/paper_src/2018.iros.ood.source/main/tf-faster-rcnn/tools/../lib/nets/network.py", line 817, in create_architecture
    rois, cls_prob, bbox_pred, caption_loss = self._build_network(training)
  File "/home/anguyen/workspace/paper_src/2018.iros.ood.source/main/tf-faster-rcnn/tools/../lib/nets/network.py", line 473, in _build_network
    caption_loss = self._caption_generation(pool5, sentences, answers) # sentences is (roi_batch_size --> 256, 10): each roi has 1 sentence --> map to 1 answer
  File "/home/anguyen/workspace/paper_src/2018.iros.ood.source/main/tf-faster-rcnn/tools/../lib/nets/network.py", line 333, in _caption_generation
    output1, state1 = self.lstm1(word_emb_in, state1)  # don't care about the input image ???
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py", line 183, in __call__
    return super(RNNCell, self).__call__(inputs, state)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/base.py", line 575, in __call__
    outputs = self.call(inputs, *args, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py", line 611, in call
    lstm_matrix = self._linear1([inputs, m_prev])
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py", line 1189, in __call__
    res = math_ops.matmul(array_ops.concat(args, 1), self._weights)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py", line 1099, in concat
    return gen_array_ops._concat_v2(values=values, axis=axis, name=name)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py", line 706, in _concat_v2
    "ConcatV2", values=values, axis=axis, name=name)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 2958, in create_op
    set_shapes_for_outputs(ret)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 2209, in set_shapes_for_outputs
    shapes = shape_func(op)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 2159, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py", line 627, in call_cpp_shape_fn
    require_shape_fn)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py", line 691, in _call_cpp_shape_fn_impl
    raise ValueError(err.message)
ValueError: Dimension 0 in both shapes must be equal, but are 256 and 1 for 'vgg_16_3/vgg_16/LSTM1/LSTM1/lstm_cell/concat' (op: 'ConcatV2') with input shapes: [256,512], [1,512], [] and with computed input tensors: input[2] = <1>.
